# Compression & Quality Implementation Guide

**Quick reference for implementing compression during asset generation**

---

## TL;DR - Quality Standards

```
IMAGES:
âœ… Primary Format: AVIF (quality 80, effort 6)
âœ… Fallback Format: WebP (quality 85)
âœ… Universal Fallback: JPEG (quality 85, progressive)
âœ… All 6 size variants (150, 400, 800, 1200, 1920, 2560)
âœ… SSIM Score: â‰¥0.95 (imperceptible quality loss)

VIDEOS:
âœ… Primary: H.264 720p (CRF 23, 2500kbps)
âœ… Premium: H.264 1080p (CRF 21, 5000kbps)
âœ… Modern: VP9 WebM (CRF 31, 2000kbps)
âœ… Audio: Normalized to -16 LUFS
âœ… VMAF Score: â‰¥85 (excellent quality)

AUDIO:
âœ… Primary: MP3 192kbps
âœ… Modern: Opus 128kbps
âœ… Archive: WAV PCM
âœ… Normalized to -16 LUFS (EBU R128)
```

---

## Phase 1: Concept Generation (No Compression)

When generating concepts, skip compression for faster feedback:

```bash
# Generate concepts WITHOUT compression
npx ts-node scripts/generate-concepts.ts \
  --batch=phase1_concepts \
  --skip-compression=true \
  --keep-originals=true

# Output: Full-quality PNG/WebP
# Purpose: Rapid feedback, quality validation
# Storage: Temporary (concepts/ folder)
```

---

## Phase 2: Refinement (Minimal Compression)

During refinement, use light compression:

```bash
# Light compression for iteration
npx ts-node scripts/process-assets.ts \
  --source=concepts/ \
  --compression-level=light \
  --keep-originals=true

Quality Settings:
â”œâ”€ AVIF: quality 75 (faster processing)
â”œâ”€ WebP: quality 80 (reasonable quality)
â””â”€ JPEG: quality 80 (acceptable loss)
```

---

## Phase 3: Production (Maximum Quality with Optimization)

### Step 1: Generate Maximum Quality Source

```typescript
// scripts/generate-production-images.ts

import sharp from 'sharp';

async function generateImage(prompt: string, assetId: string) {
  // 1. Generate via Gemini at highest resolution available
  const response = await generateViaGemini(prompt, {
    model: 'gemini-3-pro-image-preview',
    resolution: '4K'  // Get highest possible quality
  });

  // 2. Save original PNG (lossless)
  const originalPath = `assets/originals/${assetId}.png`;
  await sharp(response.imageBuffer)
    .png({ compressionLevel: 9 })  // Max PNG compression
    .toFile(originalPath);

  console.log(`âœ“ Original saved: ${originalPath}`);

  return originalPath;
}
```

### Step 2: Process for All Formats & Sizes

```typescript
// scripts/process-assets.ts

async function processImageForProduction(imagePath: string, assetId: string) {
  const image = sharp(imagePath);
  const metadata = await image.metadata();

  console.log(`Processing: ${assetId} (${metadata.width}x${metadata.height})`);

  const sizeVariants = [
    { name: 'thumbnail', width: 150, height: 150 },
    { name: 'small', width: 400, height: 400 },
    { name: 'medium', width: 800, height: 800 },
    { name: 'large', width: 1200, height: 1200 },
    { name: 'full', width: 1920, height: 1920 },
    { name: 'retina', width: 2560, height: 2560 }
  ];

  // AVIF (Primary - Best compression, excellent quality)
  console.log(`\nğŸ“¦ AVIF Encoding...`);
  for (const variant of sizeVariants) {
    const avifPath = `assets/processed/${assetId}-${variant.name}.avif`;

    const { size } = await image
      .resize(variant.width, variant.height, { fit: 'inside', withoutEnlargement: true })
      .toColorspace('srgb')
      .avif({
        quality: 80,      // 80 is excellent quality with great compression
        effort: 6,        // Balance between compression ratio and speed
        lossless: false
      })
      .toFile(avifPath);

    console.log(`  âœ“ ${variant.name}: ${formatBytes(size)}`);
  }

  // WebP (Fallback - Modern, excellent quality/size)
  console.log(`\nğŸ“¦ WebP Encoding...`);
  for (const variant of sizeVariants) {
    const webpPath = `assets/processed/${assetId}-${variant.name}.webp`;

    const { size } = await image
      .resize(variant.width, variant.height, { fit: 'inside', withoutEnlargement: true })
      .toColorspace('srgb')
      .webp({
        quality: 85,      // 85 is very high quality
        effort: 6         // Maximum compression effort
      })
      .toFile(webpPath);

    console.log(`  âœ“ ${variant.name}: ${formatBytes(size)}`);
  }

  // JPEG (Universal fallback)
  console.log(`\nğŸ“¦ JPEG Encoding...`);
  for (const variant of sizeVariants) {
    const jpegPath = `assets/processed/${assetId}-${variant.name}.jpeg`;

    const { size } = await image
      .resize(variant.width, variant.height, { fit: 'inside', withoutEnlargement: true })
      .toColorspace('srgb')
      .jpeg({
        quality: 85,           // Excellent quality
        progressive: true,     // Progressive JPEG for better UX
        mozjpeg: true,        // Better compression
        optimizeScans: true,
        trellisQuantization: true,
        overshootDeringing: true
      })
      .toFile(jpegPath);

    console.log(`  âœ“ ${variant.name}: ${formatBytes(size)}`);
  }

  // Blur placeholder (for lazy loading)
  console.log(`\nğŸ“¦ Blur Placeholder...`);
  const placeholder = await image
    .resize(20, 20)
    .blur(25)
    .webp({ quality: 30 })
    .toBuffer();

  const placeholderBase64 = placeholder.toString('base64');
  console.log(`  âœ“ Placeholder: ${formatBytes(placeholderBase64.length)}`);

  // Generate metadata
  const metadata_json = generateMetadata(assetId);
  console.log(`\nğŸ“ Metadata generated`);

  return {
    assetId,
    formats: { avif: 'âœ“', webp: 'âœ“', jpeg: 'âœ“' },
    variants: sizeVariants.length,
    placeholder: `${formatBytes(placeholderBase64.length)}`
  };
}
```

### Step 3: Quality Validation

```typescript
// scripts/validate-image-quality.ts

import { SSIM } from 'ssim.js';

async function validateImageQuality(originalPath: string, compressedPath: string) {
  // Load both images
  const original = await sharp(originalPath).raw().toBuffer();
  const compressed = await sharp(compressedPath).raw().toBuffer();

  // Calculate SSIM (Structural Similarity)
  const metadata = await sharp(originalPath).metadata();
  const ssim = SSIM(original, compressed, {
    width: metadata.width,
    height: metadata.height
  });

  console.log(`SSIM Score: ${ssim.toFixed(4)}`);

  if (ssim >= 0.95) {
    console.log('âœ… Imperceptible quality loss - APPROVED');
  } else if (ssim >= 0.90) {
    console.log('âš ï¸  Very subtle quality loss - ACCEPTABLE');
  } else {
    console.log('âŒ Noticeable quality loss - REJECTED');
  }

  return ssim >= 0.90;  // Accept if â‰¥0.90
}
```

---

## Video Compression Implementation

### Step 1: Generate Video from Veo

```bash
# Generate video via Veo 3.1 (already optimized for quality)
npx ts-node scripts/generate-videos.ts \
  --model=veo-3.1-generate-preview \
  --resolution=720p \
  --duration=6s

# Output: Video file (temporary, high quality)
```

### Step 2: Normalize Audio

```bash
#!/bin/bash
# Normalize video audio to -16 LUFS

for video in input_videos/*.mp4; do
  filename=$(basename "$video" .mp4)

  # Extract audio
  ffmpeg -i "$video" -q:a 9 -n "temp/${filename}_audio.wav"

  # Normalize
  ffmpeg-normalize "temp/${filename}_audio.wav" \
    -t -16 LUFS \
    -o "temp/${filename}_normalized.wav"

  # Verify normalization
  ffmpeg -i "temp/${filename}_normalized.wav" \
    -af loudnorm=print_format=json \
    -f null - 2>&1 | grep loudness
done
```

### Step 3: Encode All Variants

```bash
#!/bin/bash
# Process video with multiple codecs and bitrates

video=$1
filename=$(basename "$video" .mp4)

echo "ğŸ“¹ Processing: $filename"

# 720p H.264 (primary streaming)
echo "  Encoding 720p H.264..."
ffmpeg -i "$video" \
  -c:v libx264 -preset medium -crf 23 \
  -maxrate 2500k -bufsize 5000k \
  -vf "scale=1280:720" \
  -c:a aac -b:a 128k \
  "output/${filename}_720p.mp4" -y

echo "  âœ“ 720p H.264 complete"

# 1080p H.264 (premium quality)
echo "  Encoding 1080p H.264..."
ffmpeg -i "$video" \
  -c:v libx264 -preset medium -crf 21 \
  -maxrate 5000k -bufsize 10000k \
  -vf "scale=1920:1080" \
  -c:a aac -b:a 192k \
  "output/${filename}_1080p.mp4" -y

echo "  âœ“ 1080p H.264 complete"

# WebM VP9 (modern efficient format)
echo "  Encoding WebM VP9..."
ffmpeg -i "$video" \
  -c:v libvpx-vp9 -b:v 2000k \
  -vf "scale=1280:720" \
  -c:a libopus -b:a 128k \
  "output/${filename}_720p.webm" -y

echo "  âœ“ WebM VP9 complete"

# HLS for adaptive streaming
echo "  Packaging HLS..."
ffmpeg -i "$video" \
  -c:v libx264 -preset medium -crf 23 \
  -vf "scale=1280:720" \
  -c:a aac -b:a 128k \
  -hls_time 6 \
  -hls_list_size 0 \
  -hls_segment_filename "output/hls/${filename}_%03d.ts" \
  "output/hls/${filename}_master.m3u8" -y

echo "  âœ“ HLS packaging complete"

# Extract thumbnails
echo "  Extracting thumbnails..."
ffmpeg -i "$video" \
  -vf "fps=1/2,scale=320:180" \
  "output/thumbs/${filename}_thumb_%02d.webp" -y

echo "  âœ“ Thumbnails complete"

# Generate poster (first frame)
echo "  Generating poster..."
ffmpeg -i "$video" \
  -vf "scale=1280:720" \
  -vframes 1 \
  "output/poster/${filename}_poster.webp" -y

echo "  âœ“ Poster complete"

echo "âœ… $filename processing complete"
```

### Step 4: Quality Validation (Video)

```bash
#!/bin/bash
# Validate video quality using VMAF

video=$1

echo "ğŸ¬ Validating video quality..."

# Calculate VMAF score
ffmpeg -i "$video" \
  -filter:v libvmaf \
  -f null - 2>&1 | grep "VMAF score"

# Expected output: "VMAF score: XX.XX"
# Target: â‰¥85 is excellent quality
```

---

## File Size Targets (Production Ready)

### Images
```
BEFORE COMPRESSION (original generated):
â”œâ”€ 4K PNG: 8-15 MB per image

AFTER COMPRESSION:
â”œâ”€ Thumbnail (150Ã—150):
â”‚  â”œâ”€ AVIF: 2-4 KB
â”‚  â”œâ”€ WebP: 3-5 KB
â”‚  â””â”€ JPEG: 4-7 KB
â”œâ”€ Small (400Ã—400):
â”‚  â”œâ”€ AVIF: 8-12 KB
â”‚  â”œâ”€ WebP: 10-15 KB
â”‚  â””â”€ JPEG: 15-20 KB
â”œâ”€ Medium (800Ã—800):
â”‚  â”œâ”€ AVIF: 20-30 KB
â”‚  â”œâ”€ WebP: 25-35 KB
â”‚  â””â”€ JPEG: 35-50 KB
â”œâ”€ Large (1200Ã—1200):
â”‚  â”œâ”€ AVIF: 40-60 KB
â”‚  â”œâ”€ WebP: 50-70 KB
â”‚  â””â”€ JPEG: 75-100 KB
â”œâ”€ Full (1920Ã—1920):
â”‚  â”œâ”€ AVIF: 80-120 KB
â”‚  â”œâ”€ WebP: 100-150 KB
â”‚  â””â”€ JPEG: 150-250 KB
â””â”€ Retina (2560Ã—2560):
   â”œâ”€ AVIF: 120-180 KB
   â”œâ”€ WebP: 150-220 KB
   â””â”€ JPEG: 200-350 KB

ALL FORMATS COMBINED PER IMAGE: ~600-900 KB
TYPICAL DELIVERY: 30-150 KB (browser-selected)

COMPRESSION RATIO: 50-98% âœ…
```

### Videos
```
BEFORE COMPRESSION (from Veo):
â”œâ”€ 6-second video: 50-100 MB

AFTER COMPRESSION:
â”œâ”€ 720p H.264: 1.5-2 MB
â”œâ”€ 1080p H.264: 3-4 MB
â”œâ”€ WebM VP9: 1.2-1.8 MB
â”œâ”€ HLS segments: 2-2.5 MB
â””â”€ Total all formats: ~8-10 MB

TYPICAL DELIVERY: ~2 MB (client-selected)

COMPRESSION RATIO: 95-98% âœ…
```

---

## Automation Script (Complete Pipeline)

```typescript
// scripts/automate-compression.ts

import sharp from 'sharp';
import { spawn } from 'child_process';

async function compressEverything() {
  console.log('ğŸš€ Starting automated compression pipeline\n');

  // Step 1: Process all images
  console.log('ğŸ“¸ Processing images...');
  const imageFiles = await getImageFiles('assets/generated');

  for (const imagePath of imageFiles) {
    const assetId = extractAssetId(imagePath);
    await processImageForProduction(imagePath, assetId);
    console.log(`âœ… ${assetId} complete\n`);
  }

  // Step 2: Process all videos
  console.log('\nğŸ¬ Processing videos...');
  const videoFiles = await getVideoFiles('assets/videos');

  for (const videoPath of videoFiles) {
    const assetId = extractAssetId(videoPath);
    await processVideoForProduction(videoPath, assetId);
    console.log(`âœ… ${assetId} complete\n`);
  }

  // Step 3: Generate quality report
  console.log('\nğŸ“Š Generating quality report...');
  const report = await generateQualityReport();
  console.log(report);

  console.log('\nâœ¨ Compression complete!');
}

// Run it
compressEverything().catch(console.error);
```

---

## NPM Commands to Add

```json
{
  "scripts": {
    "synthex:compress-images": "ts-node scripts/process-assets.ts --images",
    "synthex:compress-videos": "bash scripts/compress-videos.sh",
    "synthex:normalize-audio": "bash scripts/normalize-audio.sh",
    "synthex:validate-quality": "ts-node scripts/validate-quality.ts",
    "synthex:generate-report": "ts-node scripts/generate-compression-report.ts"
  }
}
```

---

## Quality Checklist (Use During Compression)

```
BEFORE COMPRESSION:
â˜ Image size understood (4K = 8-15 MB)
â˜ Video size understood (50-100 MB)
â˜ Original archived safely
â˜ Quality baseline documented

AFTER COMPRESSION:
â˜ AVIF primary format working
â˜ WebP fallback working
â˜ JPEG universal fallback working
â˜ All 6 image sizes generated
â˜ Image quality validated (SSIM â‰¥0.95)
â˜ Blur placeholder generated

FOR VIDEOS:
â˜ 720p H.264 generated (2.5 Mbps)
â˜ 1080p H.264 generated (5 Mbps)
â˜ WebM VP9 variant generated
â˜ HLS streaming working
â˜ Audio normalized to -16 LUFS
â˜ Thumbnails extracted (5 frames)
â˜ Poster image created
â˜ Video quality validated (VMAF â‰¥85)

FINAL:
â˜ Total image size <1 MB per asset
â˜ Total video size <10 MB per video
â˜ CDN delivery <300ms p95
â˜ Mobile friendly (<1s load)
â˜ All metadata complete
```

---

## Troubleshooting

### AVIF Encoding Too Slow
```bash
# Reduce effort level (faster but slightly larger)
avif: { quality: 80, effort: 4 }  # Default is 6

# Expected time: 5 seconds vs 30 seconds
```

### WebP Quality Not Good Enough
```bash
# Increase quality
webp: { quality: 92 }  # Instead of 85

# Note: Will increase file size by 10-20%
```

### Video Encoding Failing
```bash
# Check FFmpeg installation
ffmpeg -version

# Install FFmpeg:
# macOS: brew install ffmpeg
# Ubuntu: sudo apt-get install ffmpeg
# Windows: choco install ffmpeg
```

### Audio Loudness Verification
```bash
# Check if audio is normalized correctly
ffmpeg -i video.mp4 -af loudnorm=print_format=json -f null - 2>&1

# Look for: "Integrated: -16 LUFS" (or very close)
```

---

## Performance Impact

```
GENERATION TIME:
â”œâ”€ Images: 2-5 seconds per image (all formats)
â”œâ”€ Videos: 5-10 minutes per video (all formats)
â””â”€ Total for 56 images + 8 videos: ~4-6 hours

STORAGE IMPACT:
â”œâ”€ Before: 500+ MB (originals)
â”œâ”€ After: ~60 MB (all processed)
â””â”€ Savings: 88% âœ…

BANDWIDTH IMPACT:
â”œâ”€ Before: Full-quality delivery
â”œâ”€ After: 40-50% less bandwidth
â””â”€ Monthly savings: $40-80 âœ…

USER EXPERIENCE:
â”œâ”€ Before: 2-5 second load times
â”œâ”€ After: <300ms load times
â””â”€ Improvement: 6-16x faster âœ…
```

---

**Status**: âœ… Ready to Implement
**Next Step**: Execute Phase 1 with original uncompressed assets, then apply compression in Phase 3
